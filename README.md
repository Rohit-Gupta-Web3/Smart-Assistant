# ğŸ§  Smart Conversational Assistant with Memory

A Django + Django REST Framework-based AI chatbot that integrates HuggingFace models to hold memory-aware conversations. Frontend is designed to impress.

---

## ğŸ“¦ Project Stack

- **Backend**: Django, Django REST Framework
- **Frontend**: HTML/CSS + Bootstrap (or Gradio/React optional)
- **AI Model**: HuggingFace Transformers (e.g., DialoGPT, Falcon)
- **Database**: PostgreSQL (recommended for Render)
- **Deployment**: Render.com

---

## ğŸš€ Getting Started (Local Development)

### 1. Clone the repo

```bash
git clone https://github.com/yourusername/smart-assistant.git
cd smart-assistant
```

### 2. Create virtual environment & install requirements

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Set up environment variables

Create a `.env` file:

```
SECRET_KEY=your-secret-key
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
HUGGINGFACE_MODEL=gpt2
```

### 4. Apply migrations and run

```bash
python manage.py migrate
python manage.py runserver
```

Visit: `http://127.0.0.1:8000`

---

## ğŸ”Œ API Endpoints (DRF)

| Endpoint              | Method   | Description                            |
| --------------------- | -------- | -------------------------------------- |
| `/api/start-session/` | POST     | Start a new chat session               |
| `/api/chat/`          | POST     | Send a message and receive AI response |
| `/api/memory/`        | GET/POST | Retrieve or update session memory      |
| `/api/history/`       | GET      | View full message history              |

---

## ğŸ§  AI Model (Transformers)

In `transformers_model/model.py`, you can load your model like this:

```python
from transformers import pipeline
chatbot = pipeline("text-generation", model="gpt2")
```

Replace with `DialoGPT`, `Falcon`, or any supported conversational model.

---

## ğŸŒ Deployment to Render.com

### 1. Push code to GitHub

Make sure your code is pushed to a public or private GitHub repo.

### 2. Create a Render Web Service

- Go to [Render.com](https://render.com/)
- Click **New Web Service**
- Connect to your GitHub repo
- Use the following build settings:

**Build Command:**

```bash
pip install -r requirements.txt && python manage.py collectstatic --noinput && python manage.py migrate
```

**Start Command:**

```bash
gunicorn config.wsgi:application
```

**Environment:**

- Add environment variables in the Render dashboard (SECRET\_KEY, DEBUG=False, DATABASE\_URL, etc.)

**PostgreSQL DB:**

- Add a Render PostgreSQL service and connect `DATABASE_URL` to your Django settings.

---

## ğŸ“ Folder Structure

```
smart_assistant/
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md

â”œâ”€â”€ config/                        # Django project config
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py               # Main settings
â”‚   â”œâ”€â”€ urls.py                   # Project-level routing
â”‚   â””â”€â”€ wsgi.py / asgi.py

â”œâ”€â”€ chatbot/                      # Main app
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ admin.py
â”‚   â”œâ”€â”€ apps.py
â”‚   â”œâ”€â”€ models.py                # DB models: Session, Message, UserMemory
â”‚   â”œâ”€â”€ views.py                 # Django views
â”‚   â”œâ”€â”€ api_views.py             # Chat API endpoint
â”‚   â”œâ”€â”€ serializers.py           # (If using DRF or custom response structure)
â”‚   â”œâ”€â”€ urls.py                  # App-level URLs
â”‚   â”œâ”€â”€ forms.py                 # Input forms (if using Django forms)
â”‚   â””â”€â”€ memory.py                # Context memory handler (cache or DB based)

â”œâ”€â”€ templates/                   # HTML templates
â”‚   â”œâ”€â”€ base.html                # Layout base
â”‚   â””â”€â”€ chat.html                # Chat interface

â”œâ”€â”€ static/                      # Static files (CSS, JS, images)
â”‚   â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ js/
â”‚   â””â”€â”€ img/

â”œâ”€â”€ transformers_model/          # AI Model logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                 # Load + respond using HuggingFace
â”‚   â””â”€â”€ utils.py                 # Tokenization, cleaning, filters

â”œâ”€â”€ tests/                       # Unit and integration tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_views.py
â”‚   â””â”€â”€ test_chatbot.py

â”œâ”€â”€ .env                         # Secrets for local dev
â””â”€â”€ .gitignore

```

---

## âœ… To Do Checklist for Students

- &#x20;Implement models and API endpoints
- Add HuggingFace model integration
- Design sleek chat UI (Tailwind or Gradio)
- Deploy to Render with PostgreSQL
- Submit GitHub + live demo + README + short video

---

## ğŸ‘ Mentorship Tip

Make the assistant charming, like a product you want to show off. Think beyond basic Q&A: memory, personality, even jokes or Easter eggs!

